---
title: "Concepts for QA and AM"
subtitle: "Quality Assurance and Automation"
author: "Peter von Rohr"
date: "`r Sys.Date()`"
output:
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_html: default
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

```{r, echo=FALSE}
knitr::opts_chunk$set(odg.conv=rmddochelper::odg.graphics.conv.hook)
```


# Disclaimer
This document gives an outline of some concepts proposed in the area of quality assurance (QA) and automation (AM)


# Introduction
According to R for Data Science [@WG2017], the following model of a data science project can be proposed. 

```{r DsProjectModel,echo=FALSE, odg.conv=TRUE, odg.path="odg", odg.out.dir="png", odg.graph.cache=TRUE, fig.cap="Data Science Project Model"}
knitr::include_graphics(path = "png/DsProjectModel.png")
```

The model as defined above starts with importing the data into a statistics tool such as R. Hence, we assume that the data is available in a file in a pre-defined format or in a database in a specified set of tables. For the design of the routine analyses that will be discussed later, the process of exporting data from a given database will also be part of the model. This data export process can be thought of as a requirement of the above shown data science project model.


## Componenents
The above shown components can be explained as follows

* __Import__: data must be imported first from a file^[When data is imported from file, a data-export process might be required to extract the data. Alternatively, it would be more convenient to directly transfer the data from the database into the statistics system.] or a database
* __Tidy__: data is cleaned, verified and converted into a standard format, where each data record is on one row and each variable is represented by one column. 
* __Transform__: after tidying certain variables are transformed. Here transformation also includes the computation of new variables from existing ones
* __Visualise__: shows properties of data that are not necessarily expected, but visualisations do not scale
* __Model__: are used to answer concrete questions and do scale well
* __Communicate__: presentation of results


# Routine Data Analysis Process
In the context of the proposed concepts, the term _routine_ is defined as a data analysis task that is done using the same data science model components on a dataset that is growing over time. Hence some of the iterative components between transformation, visualisation and modelling might be replaced by a given path between the mentioned components that was determined in data science project that is done as a preparatory study for the routine data analysis. 


## Preparatory Study
Before, we can start a new data analysis that is planned to be done according to a routine schedule, we have to conduct a preparatory study that investigates a certain number of research questions. Such a preparatory study can be done according to the above given Data Science Project Model. The results of this preparatory study are not only the outcomes of the statistical analyses, but we also save the whole process of how we proceed from the input of the raw data to the statistical results. This process is defined as path between the different data science model components and it will be used in the routine data analysis. 

An example of finding such a routine process is shown below.

```{r find_routine_process, echo=FALSE}
s_graphics_file = "odg/find_routine_process.odg"
if (!file.exists(s_graphics_file)){
  rmddochelper:::odg_draft(file = s_graphics_file, package = "rmddochelper")
}

con_graphics_file <- file(s_graphics_file)
open(con_graphics_file)

close(con = con_graphics_file)
```



```{r bib, include=FALSE}
s_bib_file <- "skeleton.bib"
vec_bref <- c(bibentry(
  bibtype = "Book",
  title = "R for Data Science",
  author = c(as.person("H. Wickham"), as.person("G. Grolemund")),
  year = "2017",
  publisher = "O'Reilly",
  url = "http://r4ds.had.co.nz/",
  key = "WG2017"
))

### # output to bib file
rmddochelper::write_bib(pvec_bref = vec_bref, ps_bibfile = s_bib_file)

# create a bib file for the R packages used in this document
# knitr::write_bib(c('base', 'rmarkdown'), file = 'skeleton.bib')
```


